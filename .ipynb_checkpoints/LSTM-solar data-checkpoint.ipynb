{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 50\n",
    "train_num = 1000\n",
    "time_series = np.sin(np.arange(0, 2*train_num/10, 0.1))\n",
    "input_series = np.zeros((train_num, interval, 1))\n",
    "target_series = np.zeros((train_num, interval, 1))\n",
    "\n",
    "for i in range(train_num):\n",
    "    input_series[i, :, 0] = time_series[i: i+interval]\n",
    "    target_series[i, :, 0] = time_series[i+interval: i+interval*2]\n",
    "    \n",
    "input_series = torch.from_numpy(input_series).to(device)\n",
    "target_series = torch.from_numpy(target_series).to(device)\n",
    "\n",
    "input_size = interval\n",
    "\n",
    "X_train = input_series[:800]\n",
    "X_test = input_series[800:]\n",
    "y_train = target_series[:800]\n",
    "y_test = target_series[800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim=1, num_layers=1):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, num_layers = self.num_layers, batch_first = True)\n",
    "\n",
    "        # Define the output layer\n",
    "        self.out = nn.Linear(self.hidden_dim, output_dim)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # This is what we'll initialise our hidden state as\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device),\n",
    "                torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device))\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        input = input.float()\n",
    "        batch_size = input.shape[0]\n",
    "        lstm_out, lstm_hidden = self.lstm(input, hidden)\n",
    "        outs = []\n",
    "        for seq in range(lstm_out.size(1)):\n",
    "            outs.append(self.out(lstm_out[:, seq, :]))\n",
    "        # Only take the output from the final timetep\n",
    "        # Can pass on the entirety of lstm_out to the next layer if it is a seq2seq prediction\n",
    "        return torch.stack(outs, dim=1), lstm_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cwj/venv/local/lib/python3.5/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-373e840ef13c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/local/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/local/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "num_epochs = 500\n",
    "\n",
    "model = LSTM(input_dim= 1, hidden_dim=128, output_dim=1, num_layers=2).to(device)\n",
    "loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#####################\n",
    "# Train model\n",
    "#####################\n",
    "\n",
    "hist = np.zeros(num_epochs)\n",
    "batch_size = 20\n",
    "for t in range(num_epochs):\n",
    "    # Initialise hidden state\n",
    "    # Don't do this if you want your LSTM to be stateful\n",
    "    lstm_hidden = model.init_hidden(batch_size=batch_size)\n",
    "\n",
    "    #loss = 0\n",
    "    for b in range(40):\n",
    "        loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "        lstm_input = X_train[batch_size*b:batch_size*(b+1), :, :].view(batch_size, interval, 1)\n",
    "        lstm_out, lstm_hidden = model(lstm_input, lstm_hidden)\n",
    "        \n",
    "        target = y_train[batch_size*b:batch_size*(b+1), :, :].float()\n",
    "        loss = loss_fn(lstm_out, target)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #loss += loss_fn(lstm_out, y_train[batch_size*b:batch_size*(b+1), :, :].float())\n",
    "        \n",
    "    \n",
    "    #loss /= \n",
    "        \n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "    if t % 5 == 0:\n",
    "        print(\"Epoch \", t, \"MSE: \", loss.item())\n",
    "        hist[t] = loss.item()\n",
    "        \n",
    "\n",
    "#####################\n",
    "# Plot preds and performance\n",
    "#####################\n",
    "# plt.plot(lstm_out.cpu().detach().numpy(), label=\"Preds\")\n",
    "# plt.plot(y_train.cpu().detach().numpy(), label=\"Data\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "plt.plot(hist, label=\"Training loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "lstm_hidden = model.init_hidden(1)\n",
    "y_pred = model(X_test[0:1], lstm_hidden)\n",
    "plt.plot(y_pred[0].cpu().detach().numpy().flatten())\n",
    "plt.plot(y_test[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 50\n",
    "train_num = 1000\n",
    "time_series = np.sin(np.arange(0, 2*train_num/10, 0.1))\n",
    "input_series = np.zeros((train_num, interval, 1))\n",
    "target_series = np.zeros((train_num, interval))\n",
    "\n",
    "for i in range(train_num):\n",
    "    input_series[i, :, 0] = time_series[i: i+interval]\n",
    "    target_series[i, :] = time_series[i+interval: i+ 2*interval]\n",
    "    \n",
    "input_series = torch.from_numpy(input_series).to(device)\n",
    "target_series = torch.from_numpy(target_series).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = interval\n",
    "\n",
    "X_train = input_series[:800]\n",
    "X_test = input_series[800:]\n",
    "y_train = target_series[:800]\n",
    "y_test = target_series[800:]\n",
    "\n",
    "X_train = X_train.view([input_size, -1, 1])\n",
    "X_test = X_test.view([input_size, -1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_dim, num_layers=1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size = self.input_size, hidden_size = self.hidden_dim, num_layers=self.num_layers)\n",
    "        self.hidden = None\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.hidden_dim, device = device),\n",
    "                torch.zeros(self.num_layers, batch_size, self.hidden_dim, device = device))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Push through RNN layer (the ouput is irrelevant)\n",
    "        inputs = inputs.float()\n",
    "        _, self.hidden = self.lstm(inputs, self.hidden)\n",
    "        return self.hidden\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim, num_layers=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        # input_size=1 since the output are single values\n",
    "        self.lstm = nn.LSTM(input_size = 1, hidden_size = hidden_dim, num_layers=num_layers)\n",
    "        self.out = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, inputs, num_steps, hidden):\n",
    "        batch_size = inputs.shape[0]\n",
    "#         Convert (batch_size, output_size) to (seq_len, batch_size, output_size)\n",
    "        inputs = inputs.unsqueeze(0).float()\n",
    "        output_list = torch.zeros(batch_size, num_steps, 1, device = device)\n",
    "        \n",
    "        for i in range(num_steps):\n",
    "            # Push current input through LSTM: (seq_len=1, batch_size, input_size=1)\n",
    "            output, hidden = self.lstm(inputs, hidden)\n",
    "            # Push the output of last step through linear layer; returns (batch_size, 1)\n",
    "            output = self.out(output)\n",
    "            output_list[:,i] = output\n",
    "            inputs = output.unsqueeze(0)\n",
    "\n",
    "        return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = X_train\n",
    "outputs = y_train\n",
    "\n",
    "# 5 is the number of features of your data points\n",
    "encoder = Encoder(input_size = 1, hidden_dim=128).to(device)\n",
    "decoder = Decoder(hidden_dim = 128).to(device)\n",
    "# Create optimizers for encoder and decoder\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.1)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.1)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "num_epoch = 500\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    # Reset hidden state of encoder for current batch\n",
    "    encoder.hidden = encoder.init_hidden(inputs.shape[1])\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # Do forward pass through encoder\n",
    "    hidden = encoder(inputs)\n",
    "    \n",
    "    # Do forward pass through decoder (decoder gets hidden state from encoder)\n",
    "    output = decoder(inputs[-1,:,:], 1, hidden)\n",
    "    \n",
    "    loss = criterion(y_train[:,0].float(), output.squeeze())\n",
    "    loss.backward()\n",
    "    # Update parameters\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(output.squeeze().cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
